[atoma-service]
inference_service_url = "http://vllm:8000" # URL of the VLLM inference service, that is compatible with the the docker-compose file specs
models = ["meta-llama/Llama-3.1-70B-Instruct"]
revisions = ["main"]
service_bind_address = "0.0.0.0:8080"

[atoma-sui]
http_rpc_node_addr = "https://fullnode.testnet.sui.io:443" # Current RPC node address for testnet
atoma_db = "0x7b8f40e38698deb650519a51f9c1a725bf8cfdc074d1552a4dc85976c2b414be" # Current ATOMA DB object ID for testnet
atoma_package_id = "0xc05bae323433740c969d8cf938c48d7559490be5f8dde158792e7a0623787013" # Current ATOMA package ID for testnet
toma_package_id = "0xa1b2ce1a52abc52c5d21be9da0f752dbd587018bc666c5298f778f42de26df1d" # Current TOMA package ID for testnet
request_timeout = { secs = 300, nanos = 0 } # Some reference value
max_concurrent_requests = 10 # Some reference value
limit = 100 # Some reference value
node_small_ids = [1]  # List of node IDs under control of the node wallet
task_small_ids = []  # List of task IDs under control of the node wallet, for most cases it can be left empty
sui_config_path = "~/.sui/sui_config/client.yaml" # Path to the Sui client configuration file, by default (on Linux, or MacOS)
sui_keystore_path = "~/.sui/sui_config/sui.keystore" # Path to the Sui keystore file, by default (on Linux, or MacOS)
cursor_path = "./cursor.toml" # Path to the Sui events cursor file

[atoma-state]
database_url = "sqlite:///app/data/atoma.db"  # Path inside the container
