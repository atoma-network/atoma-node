
HF_CACHE_PATH=~/.cache/huggingface
HF_TOKEN=   # required if you want to access a gated model
ATOMA_NODE_CONFIG_PATH=./config.toml

# ----------------------------------------------------------------------------------
# atoma node configuration

# Sui Configuration
SUI_CONFIG_PATH=~/.sui/sui_config

# Atoma Node Service Configuration
ATOMA_SERVICE_PORT=3000

TRACE_LEVEL=info

# ----------------------------------------------------------------------------------
# chat completions server
CHAT_COMPLETIONS_SERVER_PORT=50000
CHAT_COMPLETIONS_MODEL=meta-llama/Llama-3.1-70B-Instruct
CHAT_COMPLETIONS_MAX_MODEL_LEN=4096 # context length

# vllm backend
VLLM_TENSOR_PARALLEL_SIZE=1 # should be equal to GPU_COUNT

# ----------------------------------------------------------------------------------
# embeddings server
EMBEDDINGS_SERVER_PORT=50001
EMBEDDINGS_MODEL=intfloat/multilingual-e5-large-instruct

# tei backend
# Choose one of these based on your GPU architecture:
# CPU:                                  TEI_IMAGE=ghcr.io/huggingface/text-embeddings-inference:cpu-1.5
# Volta:                                UNSUPPORTED
# Turing (T4, RTX 2000 series, ...):    TEI_IMAGE=ghcr.io/huggingface/text-embeddings-inference:turing-1.5
# Ampere 80 (A100, A30):                TEI_IMAGE=ghcr.io/huggingface/text-embeddings-inference:1.5
# Ampere 86 (A10, A40, ...):            TEI_IMAGE=ghcr.io/huggingface/text-embeddings-inference:86-1.5
# Ada Lovelace (RTX 4000 series, ...):  TEI_IMAGE=ghcr.io/huggingface/text-embeddings-inference:89-1.5
# Hopper (H100):                        TEI_IMAGE=ghcr.io/huggingface/text-embeddings-inference:hopper-1.5
TEI_IMAGE=ghcr.io/huggingface/text-embeddings-inference:1.5

# ----------------------------------------------------------------------------------
# image generation server
IMAGE_GENERATIONS_SERVER_PORT=50002
IMAGE_GENERATIONS_MODEL=black-forest-labs/FLUX.1-schnell
IMAGE_GENERATIONS_ARCHITECTURE=flux

# mistralrs backend
# Choose one of these based on your GPU architecture:
# CPU:                                  MISTRALRS_IMAGE=ghcr.io/ericlbuehler/mistral.rs:cpu-0.3.1
# Volta:                                UNSUPPORTED
# Turing (T4, RTX 2000 series, ...):    MISTRALRS_IMAGE=ghcr.io/ericlbuehler/mistral.rs:cuda-75-0.3.1
# Ampere 80 (A100, A30):                MISTRALRS_IMAGE=ghcr.io/ericlbuehler/mistral.rs:cuda-80-0.3.1
# Ampere 86 (A10, A40, ...):            MISTRALRS_IMAGE=ghcr.io/ericlbuehler/mistral.rs:cuda-86-0.3.1
# Ada Lovelace (RTX 4000 series, ...):  MISTRALRS_IMAGE=ghcr.io/ericlbuehler/mistral.rs:cuda-89-0.3.1
# Hopper (H100):                        MISTRALRS_IMAGE=ghcr.io/ericlbuehler/mistral.rs:cuda-90-0.3.1
MISTRALRS_IMAGE=ghcr.io/ericlbuehler/mistral.rs:cuda-80-0.3.1
